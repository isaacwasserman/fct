{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K shape: torch.Size([128, 32, 32, 32]) V shape: torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "B, Dq, Dv, Dm, h, H, W = (16, 256, 128, 256, 8, 32, 32)\n",
    "\n",
    "\n",
    "def break_into_heads(M):\n",
    "    D = M.shape[1]\n",
    "    return M.reshape(B, h, D // h, H, W).flatten(0, 1)\n",
    "\n",
    "\n",
    "Q = torch.randn(B, Dq, H, W)\n",
    "K = torch.randn(B, Dq, H, W)\n",
    "V = torch.randn(B, Dv, H, W)\n",
    "\n",
    "Q = torch.nn.functional.softmax(Q, dim=-3)\n",
    "K = torch.nn.functional.softmax(K.flatten(-2), dim=-1).reshape(B, Dq, H, W)\n",
    "\n",
    "Q = break_into_heads(Q)\n",
    "K = break_into_heads(K)  # (B * h, Dq // h, H, W)\n",
    "V = break_into_heads(V)  # (B * h, Dv // h, H, W)\n",
    "\n",
    "print(\"K shape:\", K.shape, \"V shape:\", V.shape)\n",
    "\n",
    "# K_bmm = K.flatten(-2, -1).transpose(1, 2)  # (B * h, HW, Dq // h)\n",
    "# V_bmm = V.flatten(-2, -1).transpose(1, 2)  # (B * h, HW, Dv // h)\n",
    "# KV_bmm = torch.bmm(K_bmm.permute(0, 2, 1), V_bmm)\n",
    "# print(KV_bmm.shape)\n",
    "\n",
    "# K_loop = K.flatten(-2, -1).transpose(1, 2)  # (B * h, HW, Dq // h)\n",
    "# V_loop = V.flatten(-2, -1).transpose(1, 2)  # (B * h, HW, Dv // h)\n",
    "# KV_loop = torch.zeros(KV_bmm.shape)\n",
    "\n",
    "# # (B, D0, H, W), (B, D1, H, W) -> (B, D0, D1)\n",
    "# # For each channel in D0, multiply it with each channel in D1\n",
    "# for batch in range(K.shape[0]):\n",
    "#     for k_channel in range(K.shape[1]):\n",
    "#         for v_channel in range(V.shape[1]):\n",
    "#             KV_loop[batch, k_channel, v_channel] = K_bmm[batch, :, k_channel].T @ V_bmm[batch, :, v_channel]\n",
    "\n",
    "# K_vec = K  # .permute(0, 2, 3, 1) # (B * h, Dq // h, H, W)\n",
    "# V_vec = V  # .permute(0, 2, 3, 1) # (B * h, Dv // h, H, W)\n",
    "# KV_vec = torch.zeros(KV_bmm.shape)\n",
    "# print(K_vec.shape, V_vec.shape)\n",
    "\n",
    "# for batch in range(K_vec.shape[0]):\n",
    "#     for k_channel in range(K_vec.shape[1]):\n",
    "#         for v_channel in range(V_vec.shape[1]):\n",
    "#             KV_vec[batch, k_channel, v_channel] = (K_bmm[batch, k_channel] * K_bmm[batch, v_channel]).sum()\n",
    "# map_func = torch.vmap(torch.vmap(torch.dot))\n",
    "\n",
    "# KV_vec = map_func(K_vec, V_vec)\n",
    "\n",
    "\n",
    "KV_broadcast = (K.unsqueeze(2) * V.unsqueeze(1)).sum(dim=[-1, -2])\n",
    "\n",
    "K_vmap = K\n",
    "V_vmap = V\n",
    "\n",
    "\n",
    "def mult_sum(A, B):\n",
    "    AB = A * B\n",
    "    return AB.sum()\n",
    "\n",
    "\n",
    "batched_func = torch.vmap(torch.vmap(torch.vmap(mult_sum, in_dims=(None, 0)), in_dims=(0, None)), in_dims=(0, 0))\n",
    "KV_vmap = batched_func(K_vmap, V_vmap)\n",
    "print(KV_vmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_pool_to_resolution(x, output_resolution=3):\n",
    "    a = torch.nn.functional.interpolate(x, size=(output_resolution, output_resolution), mode=\"nearest\")\n",
    "    a = a * (output_resolution**2)\n",
    "    return a\n",
    "\n",
    "\n",
    "k = 3\n",
    "KV_kernels = K.unsqueeze(2) * V.unsqueeze(1)  # (B * h, Dq // h, Dv // h, H, W)\n",
    "KV_kernels = KV_kernels.flatten(0, 1)  # (B * h * Dq // h, Dv // h, H, W)\n",
    "KV_kernels = sum_pool_to_resolution(KV_kernels, output_resolution=k)  # (B * h * Dq // h, Dv // h, k, k)\n",
    "KV_kernels = KV_kernels.reshape(B * h, Dq // h, Dv // h, k, k)  # (B * h, Dq // h, Dv // h, k, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
